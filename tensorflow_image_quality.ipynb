{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow script mode training and serving\n",
    "\n",
    "Script mode is a training script format for TensorFlow that lets you execute any TensorFlow training script in SageMaker with minimal modification. The [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) handles transferring your script to a SageMaker training instance. On the training instance, SageMaker's native TensorFlow support sets up training-related environment variables and executes your training script. In this tutorial, we use the SageMaker Python SDK to launch a training job and deploy the trained model.\n",
    "\n",
    "In addition, this notebook demonstrates how to perform real time inference with the [SageMaker TensorFlow Serving container](https://github.com/aws/sagemaker-tensorflow-serving-container). The TensorFlow Serving container is the default inference method for script mode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment\n",
    "\n",
    "Let's start by setting up the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for distributed training\n",
    "\n",
    "At the end of the training job we have added a step to export the trained model to the path stored in the environment variable ``SM_MODEL_DIR``, which always points to ``/opt/ml/model``. This is critical because SageMaker uploads all the model artifacts in this folder to S3 at end of training.\n",
    "\n",
    "Here is the entire script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "estimator = TensorFlow(base_job_name='imagequality',\n",
    "                       entry_point='imagequality_keras_sm.py',\n",
    "                       source_dir='imagequality',\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters={'epochs' : 1,'batch-size' : 200},\n",
    "                       train_instance_count=1, train_instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard is at https://rekognitioncustomlabel.notebook.ap-southeast-1.sagemaker.aws/proxy/6006/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train' :  's3://waynetoh-ml/ava_dataset/train',\n",
    "             'validation' :  's3://waynetoh-ml/ava_dataset/validation',\n",
    "             'eval' :  's3://waynetoh-ml/ava_dataset/eval'})\n",
    "\n",
    "#Tensorboard is not supported with script mode. You can run the following command: \n",
    "#tensorboard --logdir s3://sagemaker-ap-southeast-1-284245693010/cifar10-2020-04-27-02-17-46-611/model --host localhost --port 6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deploy the trained model to an endpoint\n",
    "\n",
    "The `deploy()` method creates a SageMaker model, which is then deployed to an endpoint to serve prediction requests in real time. We will use the TensorFlow Serving container for the endpoint, because we trained with script mode. This serving container runs an implementation of a web server that is compatible with SageMaker hosting protocol. The [Using your own inference code]() document explains how SageMaker runs inference containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge',endpoint_type='tensorflow-serving')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke the endpoint\n",
    "\n",
    "Let's download the training data and use that as input for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from matplotlib.pyplot import imshow, figure\n",
    "from tensorflow.python.keras.preprocessing.image import load_img\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "aws s3 cp s3://waynetoh-ml/shopee_dataset/keyboard /tmp\n",
    "    \n",
    "test_image = load_img(\"/tmp/cb2a641916ef65c5a1668eb4e5a9be0b.jpg\", target_size=(224, 224))\n",
    "test_image_array = np.array(test_image).reshape((1, 224, 224, 3))\n",
    "figure()    \n",
    "imshow(test_image)\n",
    "\n",
    "scores = predictor.predict(test_image_array)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from matplotlib.pyplot import imshow, figure\n",
    "from tensorflow.python.keras.preprocessing.image import load_img\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# calculate mean score for AVA dataset\n",
    "def mean_score(scores):\n",
    "    si = np.arange(1, 11, 1)\n",
    "    mean = np.sum(scores * si)\n",
    "    return mean\n",
    "\n",
    "# calculate standard deviation of scores for AVA dataset\n",
    "def std_score(scores):\n",
    "    si = np.arange(1, 11, 1)\n",
    "    mean = mean_score(scores)\n",
    "    std = np.sqrt(np.sum(((si - mean) ** 2) * scores))\n",
    "    return std\n",
    "\n",
    "\n",
    "for i in range(3,9):\n",
    "    \n",
    "    test_image = load_img(\"/home/ec2-user/ava_dataset/images/95827\" + str(i) +\".jpg\", target_size=(224, 224))\n",
    "    test_image_array = np.array(test_image).reshape((1, 224, 224, 3))\n",
    "    figure()    \n",
    "    imshow(test_image)\n",
    "\n",
    "    scores = predictor.predict(test_image_array)\n",
    "    \n",
    "\n",
    "    # NIMA model produces a distribution of ratings for any given image, \n",
    "    # on a scale of 1 to 10, with 10 being the highest aesthetic score associated to an image.\n",
    "    # It assigns likelihoods to each of the possible scores, \n",
    "\n",
    "    mean = mean_score(scores['predictions'][0])\n",
    "    std = std_score(scores['predictions'][0])\n",
    "    \n",
    "    print(\"======= image \" + str(i) + \"=======\")\n",
    "    print(scores['predictions'][0])\n",
    "    print('Mean score =',mean)\n",
    "    print('Std score =',std)\n",
    "    \n",
    "    print(\"NIMA Score : %0.3f +- (%0.3f)\" % (mean, std))\n",
    "    \n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from matplotlib.pyplot import imshow, figure\n",
    "from tensorflow.python.keras.preprocessing.image import load_img\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# calculate mean score for AVA dataset\n",
    "def mean_score(scores):\n",
    "    si = np.arange(1, 11, 1)\n",
    "    mean = np.sum(scores * si)\n",
    "    return mean\n",
    "\n",
    "# calculate standard deviation of scores for AVA dataset\n",
    "def std_score(scores):\n",
    "    si = np.arange(1, 11, 1)\n",
    "    mean = mean_score(scores)\n",
    "    std = np.sqrt(np.sum(((si - mean) ** 2) * scores))\n",
    "    return std\n",
    "\n",
    "\n",
    "for i in range(1,10):\n",
    "    \n",
    "    test_image = load_img(\"/home/ec2-user/shopee_dataset/shopee\" + str(i) +\".png\", target_size=(224, 224))\n",
    "    test_image_array = np.array(test_image).reshape((1, 224, 224, 3))\n",
    "    figure()    \n",
    "    imshow(test_image)\n",
    "\n",
    "    scores = predictor.predict(test_image_array)\n",
    "    \n",
    "\n",
    "    # NIMA model produces a distribution of ratings for any given image, \n",
    "    # on a scale of 1 to 10, with 10 being the highest aesthetic score associated to an image.\n",
    "    # It assigns likelihoods to each of the possible scores, \n",
    "    # For a given mean valuehowever, images with a high variance seem more likely tobe edgy or subject to interpretation, \n",
    "    # while images with a lowvariance tend to use conventional styles or depict conven-tional subject matter. \n",
    "\n",
    "    mean = mean_score(scores['predictions'][0])\n",
    "    std = std_score(scores['predictions'][0])\n",
    "    \n",
    "    print(\"======= image \" + str(i) + \"=======\")\n",
    "    print(scores['predictions'][0])\n",
    "    print('Mean score =',mean)\n",
    "    print('Std score =',std)\n",
    "    \n",
    "    print(\"NIMA Score : %0.3f +- (%0.3f)\" % (mean, std))\n",
    "    \n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the prediction result from the TensorFlow 2.1 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the endpoint\n",
    "\n",
    "Let's delete the endpoint we just created to prevent incurring any extra costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
