{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Keras Image Generator in Amazon SageMaker\n",
    "\n",
    "Amazon SageMaker is a fully-managed service that provides developers and data scientists with the ability to build, train, and deploy machine learning (ML) models quickly. Amazon SageMaker removes the heavy lifting from each step of the machine learning process to make it easier to develop high-quality models. The SageMaker Python SDK makes it easy to train and deploy models in Amazon SageMaker with several different machine learning and deep learning frameworks, including TensorFlow and Keras.\n",
    "\n",
    "In this notebook, we train and host a MobileNet model using Keras. The model helps us to do a binary classification on an image.\n",
    "\n",
    "In order reduce the code required, we will make use keras.preprocessing.image.ImageDataGenerator class. This class allows you to instantiate generators of image batches via a directory. These generators can then be used with the Keras model methods that accept data generators as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we prepare the images by putting them into a training folder and 20% of images into a validation folder and upload them to an S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the images\n",
    "\n",
    "Download the images to the dataset folder. The folder structure is as such:\n",
    "- dataset\n",
    "    - training\n",
    "        - classA\n",
    "           - image1.jpg\n",
    "           - image2.jpg\n",
    "        - classB\n",
    "           - image3.jpg\n",
    "           - image4.jpg\n",
    "    - validation\n",
    "        - classA\n",
    "           - image5.jpg\n",
    "           - image6.jpg\n",
    "        - classB\n",
    "           - image7.jpg\n",
    "           - image8.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "We train a CNN model with the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker import get_execution_role\n",
    "from tensorflow.python.keras.preprocessing.image import load_img\n",
    "\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "\n",
    "\n",
    "bucket = \"YOUR_BUCKET\"\n",
    "key = \"dataset/images\"\n",
    "\n",
    "instance_type='ml.m5.xlarge' # The type of EC2 instance which will be used for training\n",
    "local_hyperparameters={\n",
    "    'epochs': 10,\n",
    "    'batch-size' : 64\n",
    "}\n",
    "\n",
    "train_input_path = \"s3://{}/{}/train/\".format(bucket, key)\n",
    "validation_input_path = \"s3://{}/{}/validation/\".format(bucket, key)\n",
    "\n",
    "estimator = TensorFlow(entry_point='image_quality_keras_main.py',\n",
    "                       source_dir='source_dir',\n",
    "                       role=role,\n",
    "                       framework_version='1.15.2',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters=local_hyperparameters,\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type=instance_type)\n",
    "\n",
    "estimator.fit({'training': train_input_path, \n",
    "               'validation': validation_input_path})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions\n",
    "\n",
    "Next we upload the model to a sagemaker endpoint and run predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=instance_type,endpoint_type='tensorflow-serving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from matplotlib.pyplot import imshow, figure\n",
    "from tensorflow.python.keras.preprocessing.image import load_img\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "    \n",
    "test_image = load_img(\"images/image1.jpg\", target_size=(224, 224))\n",
    "test_image_array = np.array(test_image).reshape((1, 224, 224, 3))\n",
    "figure()    \n",
    "imshow(test_image)\n",
    "\n",
    "scores = predictor.predict(test_image_array)\n",
    "print(scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notice": "Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
